The AI Council's meeting on August 3, 2025, focused on refining a predictive model. Key topics included:

  * **Adjusted R-squared:** They introduced Adjusted R-squared as a metric to penalize R-squared for models using highly collinear or irrelevant features, providing a more accurate measure of model fit. They noted that a lower Adjusted R-squared compared to R-squared indicates the presence of less important features.
  * **Multicollinearity and VIF:** The Variance Inflation Factor (VIF) was discussed as a tool to identify multicollinearity and remove unimportant features. High VIF values suggest highly correlated features, leading to unreliable regression coefficients. The formula for VIF (1 / (1 - R-squared)) was explained, where a high R-squared in the individual models built for VIF calculation indicates strong correlation.
  * **VIF Interpretation and Challenges:** VIF values less than or close to one are good, and up to five are acceptable. Values above five suggest redundancy and potential removal of the feature. They encountered "divided by zero" and infinite VIF values, particularly for one-hot encoded categorical columns, because these features can be perfectly predicted by others, leading to an R-squared of 1.
  * **Addressing VIF for Categorical Columns:** It was concluded that VIF and R-squared are primarily relevant for continuous data columns, as their underlying regression models and evaluation metrics are not suitable for categorical data. For categorical columns, they relied on the correlation matrix for feature selection.
  * **Model Refinement:** They refined the model by dropping highly correlated categorical columns based on the correlation matrix, as VIF was unreliable for these. The refined "Model B" achieved similar accuracy with fewer features, making it more efficient.
  * **Model Saving and Reuse:** The `joblib` library was used to save the trained model ("Model B") as `bigM.pickle` for reuse.
  * **Prediction Issues:** Initially, they faced issues during prediction due to a mismatch between scaled data used for training and unscaled data used for prediction, and inconsistent feature types. This emphasized the need to save and load the `scaler` artifact alongside the model.
  * **Data Preprocessing for Prediction:** They detailed how to convert raw user input (11 values) into the 38 features required by the model, including handling numerical, categorical, and one-hot encoded features. They resolved an issue with the `outlet identifier` column that was creating extra columns due to incorrect type casting.
  * **Future Steps:** The AI Council plans to demonstrate creating a user interface and implementing the model via a Flask API.
